{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from meteo_scraping import data_downloader, compute_coordinates\n",
    "from data_manage import data_handler, remove_header, replace_failed_download\n",
    "import numpy as np\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define all necessary parameters to download and handle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#related to data download \n",
    "start_date, end_date = \"2017-01-01\",\"2022-01-01\"\n",
    "reference_coord = (53.042004, 7.105163)\n",
    "d_x, d_y  = 17, 17\n",
    "km_on_x, km_on_y = 30*(d_x-1), 30*(d_y-1)\n",
    "\n",
    "\n",
    "#related to data handle\n",
    "window_enc = 24\n",
    "window_dec = 8\n",
    "horizon = 1\n",
    "jump = 9\n",
    "keep_columns_inputs = ['windspeed_10m (km/h)',\n",
    "                       'windspeed_100m (km/h)',\n",
    "                       'windgusts_10m (km/h)',\n",
    "                       'winddirection_10m (°)',\n",
    "                       'winddirection_100m (°)', #wind related\n",
    "                       \n",
    "                       'temperature_2m (°C)',\n",
    "                       'apparent_temperature (°C)', #temperature related\n",
    "                       \n",
    "                       #'relativehumidity_2m (%)', #humidity related\n",
    "                       \n",
    "                       'diffuse_radiation (W/m²)', \n",
    "                       'shortwave_radiation (W/m²)',\n",
    "                       'direct_radiation (W/m²)', #radiation related\n",
    "                       \n",
    "                       'pressure_msl (hPa)',\n",
    "                       'surface_pressure (hPa)', #pressure related\n",
    "                       \n",
    "                       'cloudcover_low (%)',\n",
    "                       'cloudcover_mid (%)', \n",
    "                       'cloudcover_high (%)'] #cloudover related\n",
    "\n",
    "keep_columns_labels = ['windspeed_100m (km/h)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "take a moment to look if numpy data (or csv files) and json meta-info are available",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m'\u001b[39m\u001b[39mtake a moment to look if numpy data (or csv files) and json meta-info are available\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: take a moment to look if numpy data (or csv files) and json meta-info are available"
     ]
    }
   ],
   "source": [
    "assert False, 'take a moment to look if numpy data (or csv files) and json meta-info are available'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_csv_data_available = True\n",
    "is_npy_data_available = False\n",
    "is_json_metainfo_available = False\n",
    "\n",
    "data_path = \"C:\\Stuffs\\Tesi Samuele\\ConvLSTM\\data\" #specify without ending \\  path for csv files\n",
    "npy_path = 'C:\\Stuffs\\Tesi Samuele\\ConvLSTM\\data_npy' #path for npy data\n",
    "json_path = 'C:\\Stuffs\\Tesi Samuele\\ConvLSTM\\info_json' #path for json meta info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coordinates = compute_coordinates( reference_coord, km_on_x, km_on_y, d_x, d_y ) \n",
    "\n",
    "my_file = open(\"coordinates_17x17.txt\", \"r\")\n",
    "coordinates_str= my_file.read()\n",
    "my_file.close()\n",
    "coordinates_str=coordinates_str[1:-1].replace('(','').replace(')','').replace(' ','').replace('\\n','').split(',')\n",
    "coordinates=[]\n",
    "for i in range(int(len(coordinates_str)/2)):\n",
    "    coordinates.append( ( float(coordinates_str[2*i]), float(coordinates_str[2*i + 1]) ) )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eventually download data (if not yet downloaded); data downloader always returns a list with coordinates tuples, used in data handle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    assert not is_csv_data_available\n",
    "    downloaded_coordinates, failed_download = data_downloader(start_date, end_date, coordinates, data_path)\n",
    "    remove_header(data_path)\n",
    "    try:\n",
    "        assert len(failed_download) == 0\n",
    "    except:\n",
    "        print('some files have not been downloaded properly!')\n",
    "        replace_failed_download ((d_x, d_y), coordinates, failed_download )\n",
    "        assert len(os.listdir(data_path)) == d_x*d_y, 'still something wrong'\n",
    "        is_csv_data_available = True\n",
    "        pass\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tensors as numpy arrays from downloaded csv files, if not available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_npy_data_available:\n",
    "    train_data, test_data, info = data_handler (  data_path, coordinates, d_x, d_y, \n",
    "                        window_enc, horizon, window_dec, jump,\n",
    "                        keep_columns_inputs,\n",
    "                        keep_columns_labels  )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If numpy data are not already available, store them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    assert not is_npy_data_available\n",
    "    enc_in_train, dec_in_train, dec_out_train = train_data\n",
    "    np.save(f\"{npy_path}\\enc_in_train.npy\", enc_in_train)\n",
    "    np.save(f\"{npy_path}\\dec_in_train.npy\", dec_in_train)\n",
    "    np.save(f\"{npy_path}\\dec_out_train.npy\", dec_out_train)\n",
    "\n",
    "\n",
    "    enc_in_test, dec_in_test, dec_out_test = test_data\n",
    "    np.save(f\"{npy_path}\\enc_in_test.npy\", enc_in_test)\n",
    "    np.save(f\"{npy_path}\\dec_in_test.npy\", dec_in_test)\n",
    "    np.save(f\"{npy_path}\\dec_out_test.npy\", dec_out_test)\n",
    "\n",
    "\n",
    "    enc_in_min, enc_in_max, dec_in_min, dec_in_max = [ info[name] for name in list(info.keys())[2:] ]\n",
    "    np.save(f\"{npy_path}\\enc_in_min.npy\", enc_in_min)\n",
    "    np.save(f\"{npy_path}\\enc_in_max.npy\", enc_in_max)\n",
    "    np.save(f\"{npy_path}\\dec_in_min.npy\", dec_in_min)\n",
    "    np.save(f\"{npy_path}\\dec_in_max.npy\", dec_in_max)\n",
    "    \n",
    "    n_inputs, n_outputs = [info[name] for name in list(info.keys())[:2] ]\n",
    "    np.save(f\"{npy_path}\\in_out_features.npy\", np.array([n_inputs, n_outputs]))\n",
    "    \n",
    "    is_npy_data_available  = True \n",
    "    \n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    assert is_npy_data_available\n",
    "    n_inputs, n_outputs = np.load(npy_path+'\\in_out_features.npy')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    assert not is_json_metainfo_available\n",
    "    assert len(os.listdir(json_path)) == 0, 'you told json meta-info are not available, but something was found in json meta-info path'\n",
    "    meta_info = {}\n",
    "    meta_info['start_date']=start_date\n",
    "    meta_info['end_date']=end_date\n",
    "    meta_info['reference_coord']=reference_coord\n",
    "    meta_info['window_enc']=window_enc\n",
    "    meta_info['window_dec']=window_dec\n",
    "    meta_info['horizon']=horizon\n",
    "    meta_info['jump']=jump\n",
    "    meta_info['keep_columns_inputs']=keep_columns_inputs\n",
    "    meta_info['keep_columns_labels']=keep_columns_labels\n",
    "    meta_info['d_x'] = d_x\n",
    "    meta_info['d_y'] = d_y\n",
    "    meta_info['km_on_x']=km_on_x\n",
    "    meta_info['km_on_y']=km_on_y\n",
    "    meta_info['n_inputs']=n_inputs.item()\n",
    "    meta_info['n_outputs']=n_outputs.item()\n",
    "    meta_info['coordinates']=coordinates\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_path+'\\data_meta_info.json', 'w') as fp:\n",
    "    json.dump(meta_info, fp, indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions to run on Colab\n",
    "\n",
    "1) load scripts on Drive ('/content/drive/MyDrive/TESI_SAMU/MyTests/Scripts');\n",
    "2) load data_meta_info.json on Drive ('/content/drive/MyDrive/TESI_SAMU/MyTests/MetaInfo');\n",
    "3) load npy data on Drive ('/content/drive/MyDrive/TESI_SAMU/MyTests/Data');\n",
    "4) run ConvLSTM_train.ipynb on Colab to train the model (with GPU device);\n",
    "5) run ConvLSTM_forecast.ipynb on Colab to get test(forecast) results (with CPU device);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 24 2022, 14:07:00) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "272e3a57ed5b92d25f90582d492c7fff8c4a6422990056b942a16d6c736ec586"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
